\subsection{Emotion recognition techniques}
To integrate emotions into computing systems, researchers have developed various techniques for recognizing and interpreting human emotions. 
These techniques range from facial expression analysis and vocal tone analysis to physiological measurements and natural language processing.

\subsubsection{The basic emotions}
Before diving into the topic of recognition, first let's define what we can recognize. In the book "Emotional Intelligence" by Daniel Goleman \cite*{goleman},
he identifies several basic emotions that are universally experienced by individuals across different cultures.
These basic emotions include:

\begin{enumerate}
    \item Happiness: Happiness is a positive emotional state characterized by feelings of joy, contentment, and satisfaction.
    It is associated with positive experiences, achievements, and pleasant circumstances.
    \item Sadness: Sadness is a negative emotional state typically associated with feelings of sorrow, grief, and melancholy. 
    It often arises in response to loss, disappointment, or separation from loved ones.
    \item Anger: Anger is a powerful and intense emotion characterized by feelings of displeasure, frustration, and hostility.
    It arises in response to perceived injustices, threats, or frustrations.
    \item Fear: Fear is an emotional response to perceived danger or threat. It triggers a heightened state of alertness and prepares the body for fight, flight, or freeze responses. 
    Fear can stem from actual physical danger or from psychological or social factors.
    \item Disgust: Disgust is an emotion that arises in response to offensive or repulsive stimuli. 
    It is associated with feelings of aversion, revulsion, and the desire to avoid or reject something distasteful.
    \item Surprise: Surprise is an emotion experienced when something unexpected or unfamiliar occurs. 
    It is characterized by a brief state of astonishment or wonder, often accompanied by physiological reactions like widened eyes or an open mouth.
    \item Contempt: Contempt is an emotion that involves feelings of scorn, disrespect, or superiority toward someone or something considered inferior or unworthy.
    It often arises from a sense of moral or social superiority.
\end{enumerate}

While these emotions are considered foundational, it is important to note that the emotional landscape is rich and nuanced, and individuals can experience
a broad spectrum of emotions that go beyond these basic categories. 
Additionally, it is worth noting that from the definition of emotion, we can often discern observable traits that are common among individuals, aiding us in identifying specific emotions.
For instance, surprise is commonly recognized by the presence of an open mouth.

\subsection{Techniques overview}

\subsubsection{Natural Language Processing}
Natural Language Processing (NLP) techniques enable computers to analyze and interpret emotions expressed through text.
Sentiment analysis and emotion classification models employ machine learning algorithms to detect emotional content in written or spoken language, such as customer reviews, 
 social media posts, and chat conversations.
By understanding the emotional tone of text, affective computing systems can provide more personalized and contextually relevant responses.
\subsubsection{Vocal Tone Analysis}
Vocal tone analysis involves extracting acoustic features from speech signals, such as pitch, intensity, and rhythm. 
Machine learning algorithms can then analyze these features to determine the emotional states expressed in speech.
Emotion recognition from vocal cues finds applications in call center analysis, voice assistants, and emotion-aware systems.
\subsubsection{Facial Expression Analysis}
Techniques such as facial action coding systems (FACS) and automated facial expression analysis algorithms utilize machine learning and 
computer vision to detect and classify facial expressions. 
These algorithms analyze factors such as muscle movements, facial landmarks, and spatial relationships to recognize emotions.
\subsubsection{Physiological Measurements}\label{sec:physiological-measurements}
Techniques for emotion recognition can leverage physiological measurements, including heart rate, skin conductance, respiration rate, and brain activity. 
Wearable devices, such as biosensors and electroencephalography (EEG) headsets, can capture these physiological signals and provide insights into the user's emotional state. 
Machine learning algorithms can then process and analyze the data to infer emotions, offering potential applications in healthcare, stress management, and affective computing research.
\subsubsection{Multimodal Fusion}
Recognizing emotions accurately often requires considering multiple modalities simultaneously. 
Multimodal fusion techniques combine information from different sources, such as facial expressions, vocal cues, and physiological signals,
to improve the robustness and accuracy of emotion recognition.
By integrating data from multiple modalities, affective computing systems can gain a more comprehensive understanding of human emotions and provide more nuanced responses.
